{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pp68FAQf9aMN"
   },
   "source": [
    "# Sarcasm Detection\n",
    " **Acknowledgement**\n",
    "\n",
    "Misra, Rishabh, and Prahal Arora. \"Sarcasm Detection using Hybrid Neural Network.\" arXiv preprint arXiv:1908.07414 (2019).\n",
    "\n",
    "**Required Files given in below link.**\n",
    "\n",
    "https://drive.google.com/drive/folders/1xUnF35naPGU63xwRDVGc-DkZ3M8V5mMk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S3Wj_mIZ8S3K"
   },
   "source": [
    "## Install `Tensorflow2.0` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jW2Uk8otQvi8",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!!pip uninstall tensorflow\n",
    "#!pip install tensorflow==2.0.0\n",
    "# already at tensorflow 2.0\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "#!pip install google-colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9kv9tyJ77eF"
   },
   "source": [
    "## Get Required Files from Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "D0O_n6OIEVyL",
    "outputId": "3d02fc9c-2fb9-4e05-d74a-a0f457b5e601"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive/')\n",
    "#Already downloded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mgRpOvFMjKR"
   },
   "outputs": [],
   "source": [
    "#Set your project path \n",
    "project_path =  'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WXYwajPeQbRq"
   },
   "source": [
    "#**## Reading and Exploring Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vAk6BRUh8CqL"
   },
   "source": [
    "## Read Data \"Sarcasm_Headlines_Dataset.json\". Explore the data and get  some insights about the data. ( 4 marks)\n",
    "Hint - As its in json format you need to use pandas.read_json function. Give paraemeter lines = True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "StSLB-T8PuGr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(project_path + 'Sarcasm_Headlines_Dataset.json', lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26709, 3)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(df.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26709 entries, 0 to 26708\n",
      "Data columns (total 3 columns):\n",
      "article_link    26709 non-null object\n",
      "headline        26709 non-null object\n",
      "is_sarcastic    26709 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 626.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_sarcastic\n",
      "0    14985\n",
      "1    11724\n",
      "Name: is_sarcastic, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23f6c43d9b0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(df.groupby([\"is_sarcastic\"]) [\"is_sarcastic\"].count())\n",
    "df[\"is_sarcastic\"].value_counts().plot.bar(title='Freq distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length of headline in data is 10.\n"
     ]
    }
   ],
   "source": [
    "print('Average word length of headline in data is {0:.0f}.'.format(np.mean(df['headline'].apply(lambda x: len(x.split())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Most common trigrams in the headline where it is sarcastic\n",
    "\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "\n",
    "text = ' '.join(df.loc[df.is_sarcastic == 1, 'headline'].values)\n",
    "text_trigrams = [i for i in ngrams(text.split(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('new', 'study', 'finds'), 33),\n",
       " (('in', 'front', 'of'), 22),\n",
       " (('state', 'of', 'the'), 20),\n",
       " (('of', 'the', 'union'), 19),\n",
       " (('majority', 'of', 'americans'), 18),\n",
       " (('new', 'line', 'of'), 16),\n",
       " (('for', 'first', 'time'), 16),\n",
       " (('in', 'middle', 'of'), 16),\n",
       " (('announces', 'plans', 'to'), 16),\n",
       " (('report:', 'majority', 'of'), 16),\n",
       " ((\"can't\", 'wait', 'to'), 15),\n",
       " (('announces', 'plan', 'to'), 13),\n",
       " ((\"'game\", 'of', \"thrones'\"), 12),\n",
       " (('has', 'no', 'idea'), 12),\n",
       " (('just', 'going', 'to'), 12),\n",
       " (('running', 'out', 'of'), 11),\n",
       " (('area', 'man', 'has'), 11),\n",
       " (('looking', 'forward', 'to'), 11),\n",
       " (('going', 'to', 'be'), 10),\n",
       " (('of', 'americans', 'would'), 10),\n",
       " (('first', 'time', 'in'), 9),\n",
       " (('no', 'one', 'in'), 9),\n",
       " (('can', 'already', 'tell'), 9),\n",
       " (('to', 'find', 'out'), 9),\n",
       " (('up', 'all', 'night'), 9),\n",
       " (('get', 'out', 'of'), 9),\n",
       " (('finds', 'majority', 'of'), 9),\n",
       " (('in', 'order', 'to'), 9),\n",
       " (('not', 'sure', 'how'), 9),\n",
       " (('to', 'white', 'house'), 9)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(text_trigrams).most_common(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observations\n",
    "    1. Column article_link has non related data and is of no use from model's perspective. Can be dropped.\n",
    "    2. We have more non sarcastic values than sarcastic ones.\n",
    "    3. Looks like we have too many common words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6pXf7A78E2H"
   },
   "source": [
    "## Drop `article_link` from dataset. ( 2 marks)\n",
    "As we only need headline text data and is_sarcastic column for this project. We can drop artical link column here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLSVsvrlP9qD"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/advancing...</td>\n",
       "      <td>advancing the world's women</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/how-meat-...</td>\n",
       "      <td>the fascinating case for eating lab-grown meat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/boxed-col...</td>\n",
       "      <td>this ceo will send your kids to school, if you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://politics.theonion.com/top-snake-handle...</td>\n",
       "      <td>top snake handler leaves sinking huckabee camp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/fridays-m...</td>\n",
       "      <td>friday's morning email: inside trump's presser...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "5  https://www.huffingtonpost.com/entry/advancing...   \n",
       "6  https://www.huffingtonpost.com/entry/how-meat-...   \n",
       "7  https://www.huffingtonpost.com/entry/boxed-col...   \n",
       "8  https://politics.theonion.com/top-snake-handle...   \n",
       "9  https://www.huffingtonpost.com/entry/fridays-m...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  \n",
       "5                        advancing the world's women             0  \n",
       "6     the fascinating case for eating lab-grown meat             0  \n",
       "7  this ceo will send your kids to school, if you...             0  \n",
       "8  top snake handler leaves sinking huckabee camp...             1  \n",
       "9  friday's morning email: inside trump's presser...             0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['article_link'], axis=1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    former versace store clerk sues over secret 'b...\n",
       "1    the 'roseanne' revival catches up to our thorn...\n",
       "2    mom starting to fear son's web series closest ...\n",
       "3    boehner just wants wife to listen, not come up...\n",
       "4    j.k. rowling wishes snape happy birthday in th...\n",
       "5                          advancing the world's women\n",
       "6       the fascinating case for eating lab-grown meat\n",
       "7    this ceo will send your kids to school, if you...\n",
       "8    top snake handler leaves sinking huckabee camp...\n",
       "9    friday's morning email: inside trump's presser...\n",
       "Name: headline, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['headline'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0h6IOxU8OdH"
   },
   "source": [
    "## Get the Length of each line and find the maximum length. ( 4 marks)\n",
    "As different lines are of different length. We need to pad the our sequences using the max length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BRAsChZAQmr3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         78\n",
      "1         84\n",
      "2         79\n",
      "3         84\n",
      "4         64\n",
      "5         27\n",
      "6         46\n",
      "7         67\n",
      "8         50\n",
      "9         59\n",
      "10        63\n",
      "11        59\n",
      "12        70\n",
      "13        64\n",
      "14        51\n",
      "15        64\n",
      "16        88\n",
      "17        50\n",
      "18        58\n",
      "19        20\n",
      "20        50\n",
      "21       111\n",
      "22        66\n",
      "23        42\n",
      "24        71\n",
      "25        37\n",
      "26        58\n",
      "27        22\n",
      "28        57\n",
      "29        40\n",
      "        ... \n",
      "26679     74\n",
      "26680     83\n",
      "26681     72\n",
      "26682     61\n",
      "26683     58\n",
      "26684     83\n",
      "26685     46\n",
      "26686     79\n",
      "26687     59\n",
      "26688     92\n",
      "26689     67\n",
      "26690     60\n",
      "26691     77\n",
      "26692     38\n",
      "26693     55\n",
      "26694     60\n",
      "26695     74\n",
      "26696     67\n",
      "26697     74\n",
      "26698     76\n",
      "26699     63\n",
      "26700     72\n",
      "26701     40\n",
      "26702     72\n",
      "26703     59\n",
      "26704     36\n",
      "26705     23\n",
      "26706     21\n",
      "26707     60\n",
      "26708     33\n",
      "Name: headline_length, Length: 26709, dtype: int64\n",
      "Headline column max length is  254\n"
     ]
    }
   ],
   "source": [
    "df.shape\n",
    "df['headline_length'] = df['headline'].apply(len)\n",
    "print(df['headline_length'])\n",
    "\n",
    "# print the maximum length\n",
    "print('Headline column max length is ', max(df.headline.map(str).apply(len)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VPPd0YuPXi2M"
   },
   "source": [
    "#**## Modelling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "35abKfRx8as3"
   },
   "source": [
    "## Import required modules required for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVel73hYEV4r"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ziybaD1RdD9"
   },
   "source": [
    "# Set Different Parameters for the model. ( 2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPw9gAN_EV6m"
   },
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "maxlen = 254\n",
    "embedding_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9abSe-bM8fn9"
   },
   "source": [
    "## Apply Keras Tokenizer of headline column of your data.  ( 4 marks)\n",
    "Hint - First create a tokenizer instance using Tokenizer(num_words=max_features) \n",
    "And then fit this tokenizer instance on your data column df['headline'] using .fit_on_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T9Ad26HfTFMS"
   },
   "outputs": [],
   "source": [
    "for idx,row in df.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')\n",
    "    \n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(df['headline'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Ffi63KsST3P"
   },
   "source": [
    "# Define X and y for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnjxBdqmSS4s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 26709\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0  307  678 3336 2297   47  381 2575    5\n",
      " 2576 8433]\n",
      "Number of Labels:  26709\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(df['headline'])\n",
    "X = pad_sequences(X, maxlen = maxlen)\n",
    "y = np.asarray(df['is_sarcastic'])\n",
    "\n",
    "print(\"Number of Samples:\", len(X))\n",
    "print(X[0])\n",
    "print(\"Number of Labels: \", len(y))\n",
    "print(y[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJLyKg-98rH_"
   },
   "source": [
    "## Get the Vocabulary size ( 2 marks)\n",
    "Hint : You can use tokenizer.word_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-2w0gHEUUIo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29657"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words = len(tokenizer.word_index)+1\n",
    "num_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5hjeMi40XcB1"
   },
   "source": [
    "#**## Word Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bUF1TuQa8ux0"
   },
   "source": [
    "## Get Glove Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vq5AIfRtMeZh"
   },
   "outputs": [],
   "source": [
    "glove_file = project_path + \"glove.6B.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJLX_n2WMecA"
   },
   "outputs": [],
   "source": [
    "#Extract Glove embedding zip file\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(glove_file, 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9IuXlu8-U3HG"
   },
   "source": [
    "# Get the Word Embeddings using Embedding file as given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elZ-T5aFGZmZ"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = 'data/glove.6B.200d.txt'\n",
    "\n",
    "embeddings = {}\n",
    "for o in open(EMBEDDING_FILE,encoding=\"utf8\"):\n",
    "    word = o.split(\" \")[0]\n",
    "    # print(word)\n",
    "    embd = o.split(\" \")[1:]\n",
    "    embd = np.asarray(embd, dtype='float32')\n",
    "    # print(embd)\n",
    "    embeddings[word] = embd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bTPxveDmVCrA"
   },
   "source": [
    "# Create a weight matrix for words in training docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQgOhiywU9nU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((num_words, 200))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "len(embeddings.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u7IbWuEX82Ra"
   },
   "source": [
    "## Create and Compile your Model  ( 7 marks)\n",
    "Hint - Use Sequential model instance and then add Embedding layer, Bidirectional(LSTM) layer, then dense and dropout layers as required. \n",
    "In the end add a final dense layer with sigmoid activation for binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7jhsSgYXG4l"
   },
   "outputs": [],
   "source": [
    "### Embedding layer for hint \n",
    "## model.add(Embedding(num_words, embedding_size, weights = [embedding_matrix]))\n",
    "### Bidirectional LSTM layer for hint \n",
    "## model.add(Bidirectional(LSTM(128, return_sequences = True)))\n",
    "\n",
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\n",
    "#model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJFMxZwMWoTw"
   },
   "source": [
    "# Fit your model with a batch size of 100 and validation_split = 0.2. and state the validation accuracy ( 5 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZpVkajCcWnRK",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "214/214 - 495s - loss: 0.6932 - accuracy: 0.5081 - val_loss: 0.6931 - val_accuracy: 0.4946\n",
      "Epoch 2/15\n",
      "214/214 - 497s - loss: 0.6931 - accuracy: 0.5071 - val_loss: 0.6931 - val_accuracy: 0.5140\n",
      "Epoch 3/15\n",
      "214/214 - 465s - loss: 0.6931 - accuracy: 0.4987 - val_loss: 0.6931 - val_accuracy: 0.5129\n",
      "Epoch 4/15\n",
      "214/214 - 482s - loss: 0.6931 - accuracy: 0.5054 - val_loss: 0.6931 - val_accuracy: 0.5625\n",
      "Epoch 5/15\n",
      "214/214 - 488s - loss: 0.6931 - accuracy: 0.5064 - val_loss: 0.6931 - val_accuracy: 0.4622\n",
      "Epoch 6/15\n",
      "214/214 - 483s - loss: 0.6931 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.4491\n",
      "Epoch 7/15\n",
      "214/214 - 452s - loss: 0.6931 - accuracy: 0.4928 - val_loss: 0.6931 - val_accuracy: 0.4708\n",
      "Epoch 8/15\n",
      "214/214 - 446s - loss: 0.6931 - accuracy: 0.4966 - val_loss: 0.6931 - val_accuracy: 0.5227\n",
      "Epoch 9/15\n",
      "214/214 - 445s - loss: 0.6931 - accuracy: 0.4964 - val_loss: 0.6931 - val_accuracy: 0.5623\n",
      "Epoch 10/15\n",
      "214/214 - 444s - loss: 0.6931 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.4762\n",
      "Epoch 11/15\n",
      "214/214 - 445s - loss: 0.6931 - accuracy: 0.5027 - val_loss: 0.6931 - val_accuracy: 0.5264\n",
      "Epoch 12/15\n",
      "214/214 - 472s - loss: 0.6931 - accuracy: 0.5019 - val_loss: 0.6931 - val_accuracy: 0.5084\n",
      "Epoch 13/15\n",
      "214/214 - 472s - loss: 0.6931 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.4425\n",
      "Epoch 14/15\n",
      "214/214 - 406s - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6931 - val_accuracy: 0.5554\n",
      "Epoch 15/15\n",
      "214/214 - 452s - loss: 0.6931 - accuracy: 0.4981 - val_loss: 0.6931 - val_accuracy: 0.4697\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 5\n",
    "\n",
    "## Add your code here ##\n",
    "history = model.fit(X, y, epochs = 15, batch_size=batch_size, validation_split = 0.2,verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy at 0.46 is not good enough.  Let's tune the model further by changing few parameters\n",
    "1. lstm_out has been changed to 128 and we will be using weights from embedding matrix\n",
    "2. Activation function has been changed to sigmoid in place of softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, embedding_size, weights = [embedding_matrix]))\n",
    "#model.add(SpatialDropout1D(0.4))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences = True)))\n",
    "#model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, None, 200)         5931400   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 256)         336896    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, None, 1)           257       \n",
      "=================================================================\n",
      "Total params: 6,268,553\n",
      "Trainable params: 6,268,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "214/214 [==============================] - 364s 2s/step - loss: 0.6740 - accuracy: 0.5762 - val_loss: 0.6743 - val_accuracy: 0.5753\n",
      "Epoch 2/5\n",
      "214/214 [==============================] - 326s 2s/step - loss: 0.6364 - accuracy: 0.6120 - val_loss: 0.5052 - val_accuracy: 0.7903\n",
      "Epoch 3/5\n",
      "214/214 [==============================] - 328s 2s/step - loss: 0.6290 - accuracy: 0.6185 - val_loss: 0.5956 - val_accuracy: 0.6577\n",
      "Epoch 4/5\n",
      "214/214 [==============================] - 328s 2s/step - loss: 0.5170 - accuracy: 0.7632 - val_loss: 0.6413 - val_accuracy: 0.5780\n",
      "Epoch 5/5\n",
      "214/214 [==============================] - 331s 2s/step - loss: 0.4927 - accuracy: 0.7518 - val_loss: 0.4877 - val_accuracy: 0.7789\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 5\n",
    "\n",
    "## Add your code here ##\n",
    "history = model.fit(X, y, epochs = 5, batch_size=batch_size, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We ran the model for 5 epochs and val accuracy bumped to 0.77 which is far better than what we previously had\n",
    "<br>We can train model further for better accuracy  </b>\n",
    "<br><br> Running a quick check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s\n",
      "Sarcasm\n"
     ]
    }
   ],
   "source": [
    "test_headline = ['mom starting to fear son\\'s web series closest thing she will have to grandchild']\n",
    "test_headline = tokenizer.texts_to_sequences(test_headline)\n",
    "test_headline = pad_sequences(test_headline, maxlen=254, dtype='int32', value=0)\n",
    "\n",
    "sentiment = model.predict(test_headline,batch_size=1,verbose = 2)[0]\n",
    "\n",
    "if(np.argmax(sentiment) == 0):\n",
    "    print(\"Non-sarcastic\")\n",
    "else:\n",
    "    print(\"Sarcasm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "1. We are able to get accuracy of 0.45-0.5 with softmax as activation\n",
    "2. We tuned further to use sigmoid as activation function and chaging lstm vector output size and got decent accuracy of almost .78\n",
    "3. The model can be tuned further and tested with different hyperparameter values."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Sarcasm_Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
